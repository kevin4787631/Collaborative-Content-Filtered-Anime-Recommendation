# -*- coding: utf-8 -*-
"""Proyek2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Rc3IbJzo-aFq8dxY3K8ru1hed8A5hKMe

# Collaborative & Content Filtered Book Recommendation

Berdasarkan salah satu website berjudul [9 Benefits of Watching Anime That Makes You Smarter](https://animemotivation.com/benefits-of-watching-anime/), menonton anime dapat memberikan banyak keuntungan. Salah satunya adalah kita dapat mendapatkan pelajaran hidup dan mempelajari budaya Jepang.

<img src= "https://wallpaperaccess.com/full/39033.png" alt ="Anime">

___
# Importing Libraries and Dataset

## Importing Libraries

Kode berikut saya melakukan import libraries yang diperlukan pada proyek ini.
"""

import pandas as pd
import numpy as np 
import matplotlib.pyplot as plt
import os

"""Kode berikut saya menginstall library kaggle."""

! pip install -q kaggle

"""Kode berikut saya import library files dan melakukan upload file kaggle API."""

from google.colab import files

files.upload()

"""Kode berikut saya membuat folder bernama kaggle dan memasukkan file yang sebelumnya saya upload ke dalam folder tersebut."""

! mkdir ~/.kaggle

! cp kaggle.json ~/.kaggle/

"""Kode berikut saya memberi akses supaya dapat read dan write pada file kaggle."""

! chmod 600 ~/.kaggle/kaggle.json

"""Kode berikut saya men-*download* dataset yang terdapat di kaggle."""

! kaggle datasets download hernan4444/anime-recommendation-database-2020

"""Kode berikut saya mengimpor zipfile dan melakukan extract kepada dataset yang telah saya download sebelumnya."""

import zipfile,os

localZip = '/content/anime-recommendation-database-2020.zip'
zipRef = zipfile.ZipFile(localZip, 'r')
zipRef.extractall('/temp/anime')
zipRef.close()

"""Kode berikut untuk melihat daftar folder yang terdapat dalam file zip yang sudah di-*extract* sebelumnya."""

os.listdir('/temp/anime')

"""## Importing Dataset

Kode berikut digunakan untuk membaca anime.csv dan rating_complete.csv.
Saya hanya menggunakan dua data ini dikarenakan animelist.csv merupakan gabungan anime.csv dan rating_complete, sedangkan watching_status.csv tidak mengandung data yang signifikan.
"""

anime_dataset = pd.read_csv('/temp/anime/anime.csv')
rating_dataset = pd.read_csv('/temp/anime/rating_complete.csv')

"""Kode berikut digunakan untuk melihat bentuk dari dataset anime."""

anime_dataset.shape

"""Kode berikut digunakan untuk melihat bentuk dari dataset rating."""

rating_dataset.shape

"""# Data Preprocessing

Kode berikut digunakan untuk melihat 5 kolom pertama dari rating dataset.
"""

rating_dataset.head()

"""Dikarenakan jumlah data yang sangat banyak, saya akan mengambil sebagian kecil saja dari dataset."""

anime_dataset = anime_dataset[:10000]
rating_dataset=rating_dataset[:30000]

"""Kode berikut digunakan untuk melihat 5 kolom pertama dari rating dataset."""

rating_dataset.head()

"""Kode berikut digunakan untuk melihat 5 kolom pertama dari anime dataset."""

anime_dataset.head()

"""Kode berikut digunakan untuk mengidentifikasi anime yang mempunyai rating tertinggi, yaitu 10."""

rating_dataset[rating_dataset.rating == max(rating_dataset.rating)]
best_animeId = rating_dataset.anime_id[rating_dataset.rating == max(rating_dataset.rating)]
best_animeId = list(dict.fromkeys(best_animeId))

"""Kode berikut digunakan memasukkan anime yang mempunyai rating 10 ke dalam variabel best_anime."""

best_anime = []
for i in best_animeId:
    anime_name = anime_dataset.Name[anime_dataset.MAL_ID == i]
    best_anime.append(anime_name)

"""Kode berikut digunakan untuk melihat daftar 25 pertama dari variabel best_anime."""

best_anime[:25]

"""Kode berikut digunakan untuk melihat jumlah anime yang memiliki rating 10."""

len(best_anime)

"""Kode berikut digunakan untuk melihat diagram yang menunjukkan rating yang diberikan oleh pengguna. """

count = rating_dataset["rating"].value_counts()
count.plot(kind='pie', title="Rating");
 
plt.show()

"""Kode berikut digunakan untuk melihat diagram kapan sebuah anime ditayangkan."""

count = anime_dataset["Premiered"].value_counts()
count.plot(kind='pie');
 
plt.show()

"""Kode berikut digunakan untuk melihat pairplot pada dataset rating."""

import seaborn as sns
sns.pairplot(rating_dataset, diag_kind = 'kde')

"""# Content Filtered Recommendation System

Content-based filtering adalah sebuah tipe sistem rekomendasi yang mencoba untuk menebak apa yang mungkin pengguna sukai berdasarkan aktivitas pengguna tersebut. Content-based filtering membuat rekomendasi dengan menggunakan kata kunci dan atribut yang ditentukan ke objek dalam sebuah database.

##Data preparation

Kode berikut digunakan untuk drop nilai NaN pada semua dataset.
"""

anime_dataset = anime_dataset.dropna()
rating_dataset = rating_dataset.dropna()

"""Kode berikut digunakan untuk drop kolom-kolom yang memiliki nilai Unknkown pada dataset."""

anime_dataset = anime_dataset[anime_dataset.Premiered != "Unknown"]
anime_dataset = anime_dataset[anime_dataset.Studios != "Unknown"]

"""Kode berikut digunakan untuk menampilkan diagram kapan sebuah anime ditayangkan setelah melakukan cleaning dataset."""

count = anime_dataset["Premiered"].value_counts()
count.plot(kind='pie');
 
plt.show()

"""Kode berikut digunakan untuk melihat nilai null pada dataset anime."""

anime_dataset.isnull().sum()

"""Kode berikut digunakan untuk melihat nilai null pada dataset rating."""

rating_dataset.isnull().sum()

"""Karena kedua dataset sudah tidak memiliki nilai null maka dipastikan dataset sudah bersih.

Kode berikut digunakan untuk melakukan drop kolom yang memiliki duplikat.
"""

rating_dataset = rating_dataset.drop_duplicates()
anime_dataset = anime_dataset.drop_duplicates()

"""Kode berikut digunakan untuk melihat bentuk dataset anime setelah cleaning."""

anime_dataset.shape

"""Kode berikut digunakan untuk melihat bentuk dataset rating setelah cleaning."""

rating_dataset.shape

"""Kode berikut digunakan untuk melihat daftar 5 pertama dari dataset anime."""

anime_dataset.head()

"""Kode berikut digunakan untuk menampung data-data yang penting dari dataset anime ke dalam list."""

anime_name = anime_dataset.Name.tolist()
anime_id = anime_dataset.MAL_ID.tolist()
anime_studio = anime_dataset.Studios.tolist()
anime_premiered = anime_dataset.Premiered.tolist()

"""Kode berikut digunakan untuk membuat dataframe baru dari variabel-variabel yang sudah dibuat sebelumnya."""

anime = pd.DataFrame({
    'anime_id': anime_id,
    'anime_name': anime_name,
    'studio': anime_studio,
    'premiered': anime_premiered
})
anime

"""## Modeling

Kode berikut digunakan untuk mengidentifikasi kata-kata penting dari nama studio sebuah anime.
"""

from sklearn.feature_extraction.text import TfidfVectorizer

tf = TfidfVectorizer()
tf.fit(anime['studio']) 
tf.get_feature_names()

"""Kode berikut digunakan untuk melakukan transformasi dan fit ke dalam metriks dan menampilkan bentuk dari metriks tersebut."""

tfidf_matrix = tf.fit_transform(anime['studio']) 
 
tfidf_matrix.shape

"""Kode berikut digunakan untuk mengubah variable tfidf_matrix yang semula vektor menjadi metriks."""

tfidf_matrix.todense()

"""Kode berikut digunakan untuk melihat matriks dari judul anime dengan studionya."""

pd.DataFrame(
    tfidf_matrix.todense(), 
    columns=tf.get_feature_names(),
    index=anime.anime_name
).sample(10, axis=1,replace=True).sample(10, axis=0)

"""Kode berikut digunakan untuk mengidentifikasi derajat kesamaan dengan menggunakan cosine similarity."""

from sklearn.metrics.pairwise import cosine_similarity
 
cosine_sim = cosine_similarity(tfidf_matrix) 
cosine_sim

"""Kode berikut digunakan untuk membuat dataframe cosine_sim_df dengan baris dan kolomnya adalah judul anime."""

cosine_sim_df = pd.DataFrame(cosine_sim, index=anime['anime_name'], columns=anime['anime_name'])

"""Kode berikut digunakan untuk membuat rekomendasi anime sebanyak k buah, dalam kasus ini adalah 5, berdasarkan nilai cosine similarity dengan tingkat kesamaan dari yang paling tinggi."""

def studio_recommendations(i, M, items, k=5):
    ix = M.loc[:,i].to_numpy().argpartition(range(-1,-k,-1))
    closest = M.columns[ix[-1:-(k+2):-1]]
    closest = closest.drop(i, errors='ignore')
    return pd.DataFrame(closest).merge(items).head(k)

"""Kode berikut digunakan untuk menampung contoh judul anime yang telah ditonton dan menampilkannya"."""

anime_that_have_been_watched = "Naruto: Shippuuden"
anime[anime.anime_name.eq(anime_that_have_been_watched)]

"""Kode berikut digunakan untuk mendapatkan rekomendasi dari anime "Naruto: Shippuuden"."""

recommendations = studio_recommendations(anime_that_have_been_watched, cosine_sim_df, anime[['anime_name', 'studio']])

"""Kode berikut digunakan untuk melakukan drop kolom duplikat."""

recommendations = recommendations.drop_duplicates()

"""Kode berikut digunakan untuk menampilkan anime rekomendasi."""

recommendations

"""## Evaluasi

Kode berikut digunakan untuk mengidentifikasi baris anime yang telah ditonton dan studio dari anime tersebut.
"""

anime_that_have_been_watched_row = anime_dataset[anime_dataset.Name == anime_that_have_been_watched]
anime_that_have_been_watched_studio = anime_that_have_been_watched_row.iloc[0]["Studios"]

"""Kode berikut digunakan untuk menampung list studio dari varaibel recommendations."""

anime_recommendation_studio = recommendations.studio

"""Kode berikut digunakan untuk mengecek jumlah studio yang ada pada list tersebut. Jika sama maka nilai real_studio akan bertambah 1. """

real_studio = 0
for i in range(5):
    if anime_recommendation_studio[i] == anime_that_have_been_watched_studio:
        real_studio+=1

"""Kode berikut digunakan untuk mengukur akurasi dari model. Dikarenakan sebelumnya jumlah rekomendasi saya tetapkan 5 buah, maka akurasi dihitung dengan cara membaginya dengan 5 dan kali dengan 100."""

Precision = real_studio/5*100
print("Precision of the model is {}%".format(Precision))

"""Akurasi 100% menunjukkan bahwa studio yang terdapat pada rekomendasi semuanya sama.

# Collaborative Filtering Recommendation

Collaborative filtering adalah sistem rekomendasi yang membuat prediksi berdasarkan riwayat aktivitas-aktivitas dari pengguna.
Collaborative filtering cenderung mencari apa yang diinginkan pengguna untuk mengklasifikasikan pengguna-pengguna dalam cluster dengan tipe yang sama dan merekomendasikan setiap pengguna sesuai dengan preferensi clusternya.

## Data Preparation

Kode berikut digunakan untuk membuat list dari user_id dan mengubah user_id menjadi integer.
"""

user_id = rating_dataset['user_id'].unique().tolist()
user_to_user_encoded = {x: i for i, x in enumerate(user_id)}
user_encoded_to_user = {i: x for i, x in enumerate(user_id)}

"""Kode berikut digunakan untuk membuat list dari anime_id dan mengubah anime_id menjadi integer."""

anime_id = rating_dataset['anime_id'].unique().tolist()
anime_to_anime_encoded = {x: i for i, x in enumerate(anime_id)}
anime_encoded_to_anime = {i: x for i, x in enumerate(anime_id)}

rating_dataset['user'] = rating_dataset['user_id'].map(user_to_user_encoded)
rating_dataset['anime'] = rating_dataset['anime_id'].map(anime_to_anime_encoded)

"""Kode berikut digunakan untuk mengecek jumlah user dan anime"""

num_users = len(user_encoded_to_user)
print(num_users)
num_anime = len(anime_encoded_to_anime)
print(num_anime)
rating_dataset['rating'] = rating_dataset['rating'].values.astype(np.float32)

min_rating = min(rating_dataset['rating'])
max_rating = max(rating_dataset['rating'])
 
print('Number of User: {} \nNumber of Anime: {} \nMin Rating: {} \nMax Rating: {}'.format(
    num_users, num_anime, min_rating, max_rating
))

"""## Dataset Splitting

Kode berikut digunakan untuk memberi index random pada dataset.
"""

rating_dataset = rating_dataset.sample(frac=1, random_state=42)
rating_dataset

"""Kode berikut digunakan untuk melakukan pembagian data set. Dengan 0.75 data training dan 0.25 data validasi."""

x = rating_dataset[['user', 'anime']].values
 
y = rating_dataset['rating'].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values
 
train_indices = int(0.75 * rating_dataset.shape[0])
x_train, x_val, y_train, y_val = (
    x[:train_indices],
    x[train_indices:],
    y[:train_indices],
    y[train_indices:]
)
 
print(x, y)

"""## Modeling

Kode berikut digunakan untuk mengimpor library yang dibutuhkan untuk melakukan modeling.
"""

from tensorflow import keras
from tensorflow.keras import layers
import tensorflow as tf

"""Pada kode berikut saya menggunakan RecommenderNet untuk membuat model *collaborative filtering*."""

class RecommenderNet(tf.keras.Model):
 
  def __init__(self, num_users, num_anime, embedding_size, **kwargs):
    super(RecommenderNet, self).__init__(**kwargs)
    self.num_users = num_users
    self.num_anime = num_anime
    self.embedding_size = embedding_size
    self.user_embedding = layers.Embedding(
        num_users,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.user_bias = layers.Embedding(num_users, 1)
    self.anime_embedding = layers.Embedding( 
        num_anime,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.anime_bias = layers.Embedding(num_anime, 1) 
 
  def call(self, inputs):
    user_vector = self.user_embedding(inputs[:,0])
    user_bias = self.user_bias(inputs[:, 0])
    anime_vector = self.anime_embedding(inputs[:, 1])
    anime_bias = self.anime_bias(inputs[:, 1]) 
 
    dot_user_anime = tf.tensordot(user_vector, anime_vector, 2) 
 
    x = dot_user_anime + user_bias + anime_bias
    
    return tf.nn.sigmoid(x)

"""Kode berikut digunakan untuk melakukan compile pada model dengan menggunakan metrik RMSE(Root Mean Squared Error)."""

model = RecommenderNet(num_users, num_anime, 50)

model.compile(
    loss = tf.keras.losses.BinaryCrossentropy(),
    optimizer = keras.optimizers.Adam(learning_rate=0.001),
    metrics=[tf.keras.metrics.RootMeanSquaredError()]
)

"""Kode berikut digunakan untuk melakukan fit pada model dan menampungnya riwayatnya."""

history = model.fit(
    x = x_train,
    y = y_train,
    batch_size = 5,
    epochs = 20,
    validation_data = (x_val, y_val)
)

"""## Visualisasi

Kode berikut digunakan untuk menampilkan hasil fit dalam bentuk grafik.
"""

plt.plot(history.history['root_mean_squared_error'])
plt.plot(history.history['val_root_mean_squared_error'])
plt.title('Matrix Model')
plt.ylabel('RMSE')
plt.xlabel('Epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

"""## Rekomendasi

Kode berikut digunakan untuk menetapkan variabel anime_dataset dan rating_dataset.
"""

anime_dataset =  anime
rating_dataset = rating_dataset

"""Kode berikut digunakan untuk mengambil user_id secara acak dan melihat anime apa saja yang telah ia tonton."""

user_id = rating_dataset.user_id.sample(1).iloc[0]
anime_have_been_watched_by_user = rating_dataset[rating_dataset.user_id == user_id]
 
anime_have_not_been_watched_by_user = anime_dataset[anime_dataset['anime_id'].isin(anime_have_been_watched_by_user.anime_id.values)]['anime_id'] 
anime_have_not_been_watched_by_user = list(
    set(anime_have_not_been_watched_by_user)
    .intersection(set(anime_to_anime_encoded.keys()))
)
 
anime_have_not_been_watched_by_user = [[anime_to_anime_encoded.get(x)] for x in anime_have_not_been_watched_by_user]
user_encoder = user_to_user_encoded.get(user_id)
user_anime_array = np.hstack(
    ([[user_encoder]] * len(anime_have_not_been_watched_by_user), anime_have_not_been_watched_by_user)
)

"""Kode berikut digunakan untuk memberikan rekomendasi anime sebanyak 10 buah."""

ratings = model.predict(user_anime_array).flatten()
 
top_ratings_indices = ratings.argsort()[-10:][::-1]
recommended_anime_id = [
    anime_encoded_to_anime.get(anime_have_not_been_watched_by_user[x][0]) for x in top_ratings_indices
]
 
top_anime_recommended = (
    anime_have_been_watched_by_user.sort_values(
        by = 'rating',
        ascending=False
    )
    .head(5)
    .anime_id.values
)
 
anime_row = anime_dataset[anime_dataset['anime_id'].isin(top_anime_recommended)]
for row in anime_row.itertuples():
    print(row.anime_name, ':', row.studio)
 
print('----' * 12)
print('Top 10 anime Recommendation for user: {}'.format(user_id))
print('----' * 12)
 
recommended_anime = anime_dataset[anime_dataset['anime_id'].isin(recommended_anime_id)]

i=1
for row in recommended_anime.itertuples():
    print('{}. '.format(i), row.anime_name, ':', row.studio)
    i+=1